{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n",
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> all\n",
      "Command 'all' unrecognized\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> d\n",
      "\n",
      "Download which package (l=list; x=cancel)?\n",
      "  Identifier> all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Downloading collection 'all'\n",
      "       | \n",
      "       | Downloading package abc to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/abc.zip.\n",
      "       | Downloading package alpino to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/alpino.zip.\n",
      "       | Downloading package biocreative_ppi to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/biocreative_ppi.zip.\n",
      "       | Downloading package brown to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/brown.zip.\n",
      "       | Downloading package brown_tei to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/brown_tei.zip.\n",
      "       | Downloading package cess_cat to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cess_cat.zip.\n",
      "       | Downloading package cess_esp to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cess_esp.zip.\n",
      "       | Downloading package chat80 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/chat80.zip.\n",
      "       | Downloading package city_database to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/city_database.zip.\n",
      "       | Downloading package cmudict to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/cmudict.zip.\n",
      "       | Downloading package comparative_sentences to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/comparative_sentences.zip.\n",
      "       | Downloading package comtrans to /home/jovyan/nltk_data...\n",
      "       | Downloading package conll2000 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/conll2000.zip.\n",
      "       | Downloading package conll2002 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/conll2002.zip.\n",
      "       | Downloading package conll2007 to /home/jovyan/nltk_data...\n",
      "       | Downloading package crubadan to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/crubadan.zip.\n",
      "       | Downloading package dependency_treebank to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/dependency_treebank.zip.\n",
      "       | Downloading package dolch to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/dolch.zip.\n",
      "       | Downloading package europarl_raw to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/europarl_raw.zip.\n",
      "       | Downloading package floresta to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/floresta.zip.\n",
      "       | Downloading package framenet_v15 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v15.zip.\n",
      "       | Downloading package framenet_v17 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/framenet_v17.zip.\n",
      "       | Downloading package gazetteers to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/gazetteers.zip.\n",
      "       | Downloading package genesis to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/genesis.zip.\n",
      "       | Downloading package gutenberg to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/gutenberg.zip.\n",
      "       | Downloading package ieer to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ieer.zip.\n",
      "       | Downloading package inaugural to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/inaugural.zip.\n",
      "       | Downloading package indian to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/indian.zip.\n",
      "       | Downloading package jeita to /home/jovyan/nltk_data...\n",
      "       | Downloading package kimmo to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/kimmo.zip.\n",
      "       | Downloading package knbc to /home/jovyan/nltk_data...\n",
      "       | Downloading package lin_thesaurus to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/lin_thesaurus.zip.\n",
      "       | Downloading package mac_morpho to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/mac_morpho.zip.\n",
      "       | Downloading package machado to /home/jovyan/nltk_data...\n",
      "       | Downloading package masc_tagged to /home/jovyan/nltk_data...\n",
      "       | Downloading package moses_sample to /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/moses_sample.zip.\n",
      "       | Downloading package movie_reviews to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/movie_reviews.zip.\n",
      "       | Downloading package names to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/names.zip.\n",
      "       | Downloading package nombank.1.0 to /home/jovyan/nltk_data...\n",
      "       | Downloading package nps_chat to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/nps_chat.zip.\n",
      "       | Downloading package omw to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/omw.zip.\n",
      "       | Downloading package opinion_lexicon to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/opinion_lexicon.zip.\n",
      "       | Downloading package paradigms to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/paradigms.zip.\n",
      "       | Downloading package pil to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pil.zip.\n",
      "       | Downloading package pl196x to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pl196x.zip.\n",
      "       | Downloading package ppattach to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ppattach.zip.\n",
      "       | Downloading package problem_reports to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/problem_reports.zip.\n",
      "       | Downloading package propbank to /home/jovyan/nltk_data...\n",
      "       | Downloading package ptb to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ptb.zip.\n",
      "       | Downloading package product_reviews_1 to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_1.zip.\n",
      "       | Downloading package product_reviews_2 to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/product_reviews_2.zip.\n",
      "       | Downloading package pros_cons to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/pros_cons.zip.\n",
      "       | Downloading package qc to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/qc.zip.\n",
      "       | Downloading package reuters to /home/jovyan/nltk_data...\n",
      "       | Downloading package rte to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/rte.zip.\n",
      "       | Downloading package semcor to /home/jovyan/nltk_data...\n",
      "       | Downloading package senseval to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/senseval.zip.\n",
      "       | Downloading package sentiwordnet to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sentiwordnet.zip.\n",
      "       | Downloading package sentence_polarity to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sentence_polarity.zip.\n",
      "       | Downloading package shakespeare to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/shakespeare.zip.\n",
      "       | Downloading package sinica_treebank to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/sinica_treebank.zip.\n",
      "       | Downloading package smultron to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/smultron.zip.\n",
      "       | Downloading package state_union to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/state_union.zip.\n",
      "       | Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/stopwords.zip.\n",
      "       | Downloading package subjectivity to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/subjectivity.zip.\n",
      "       | Downloading package swadesh to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/swadesh.zip.\n",
      "       | Downloading package switchboard to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/switchboard.zip.\n",
      "       | Downloading package timit to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/timit.zip.\n",
      "       | Downloading package toolbox to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/toolbox.zip.\n",
      "       | Downloading package treebank to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/treebank.zip.\n",
      "       | Downloading package twitter_samples to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/twitter_samples.zip.\n",
      "       | Downloading package udhr to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/udhr.zip.\n",
      "       | Downloading package udhr2 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/udhr2.zip.\n",
      "       | Downloading package unicode_samples to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/unicode_samples.zip.\n",
      "       | Downloading package universal_treebanks_v20 to\n",
      "       |     /home/jovyan/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       | Downloading package verbnet to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/verbnet.zip.\n",
      "       | Downloading package verbnet3 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/verbnet3.zip.\n",
      "       | Downloading package webtext to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/webtext.zip.\n",
      "       | Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/wordnet.zip.\n",
      "       | Downloading package wordnet_ic to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/wordnet_ic.zip.\n",
      "       | Downloading package words to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/words.zip.\n",
      "       | Downloading package ycoe to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/ycoe.zip.\n",
      "       | Downloading package rslp to /home/jovyan/nltk_data...\n",
      "       |   Unzipping stemmers/rslp.zip.\n",
      "       | Downloading package maxent_treebank_pos_tagger to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "       | Downloading package universal_tagset to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/universal_tagset.zip.\n",
      "       | Downloading package maxent_ne_chunker to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "       | Downloading package punkt to /home/jovyan/nltk_data...\n",
      "       |   Unzipping tokenizers/punkt.zip.\n",
      "       | Downloading package book_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/book_grammars.zip.\n",
      "       | Downloading package sample_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/sample_grammars.zip.\n",
      "       | Downloading package spanish_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/spanish_grammars.zip.\n",
      "       | Downloading package basque_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/basque_grammars.zip.\n",
      "       | Downloading package large_grammars to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping grammars/large_grammars.zip.\n",
      "       | Downloading package tagsets to /home/jovyan/nltk_data...\n",
      "       |   Unzipping help/tagsets.zip.\n",
      "       | Downloading package snowball_data to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package bllip_wsj_no_aux to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "       | Downloading package word2vec_sample to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/word2vec_sample.zip.\n",
      "       | Downloading package panlex_swadesh to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package mte_teip5 to /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/mte_teip5.zip.\n",
      "       | Downloading package averaged_perceptron_tagger to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "       | Downloading package averaged_perceptron_tagger_ru to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
      "       | Downloading package perluniprops to /home/jovyan/nltk_data...\n",
      "       |   Unzipping misc/perluniprops.zip.\n",
      "       | Downloading package nonbreaking_prefixes to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "       | Downloading package vader_lexicon to\n",
      "       |     /home/jovyan/nltk_data...\n",
      "       | Downloading package porter_test to /home/jovyan/nltk_data...\n",
      "       |   Unzipping stemmers/porter_test.zip.\n",
      "       | Downloading package wmt15_eval to /home/jovyan/nltk_data...\n",
      "       |   Unzipping models/wmt15_eval.zip.\n",
      "       | Downloading package mwa_ppdb to /home/jovyan/nltk_data...\n",
      "       |   Unzipping misc/mwa_ppdb.zip.\n",
      "       | \n",
      "     Done downloading collection all\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    }
   ],
   "source": [
    "#imports and installs - will run automatically when imported into the Final_Program.ipynb\n",
    "!pip install nltk\n",
    "import nltk #for language processing\n",
    "nltk.download() #download all corpora and packages\n",
    "import nltk #import the new downloads\n",
    "from nltk.corpus import stopwords #import stopwords to remove from plot synopsis\n",
    "from nltk.tokenize import word_tokenize #import tokenize function to break up the plot\n",
    "import pandas as pd #for importing the csv into dataframes\n",
    "import requests #for later\n",
    "from IPython.display import display, HTML #for multiple displays and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def callimdblist(): #pull data from csv into dataframe\n",
    "    '''Import data from local .csv into a dataframe'''\n",
    "    imdb_top_250_english = \"IMDB_Top250Engmovies2_OMDB_Detailed.csv\" #rename for ease of calling\n",
    "    data = pd.read_csv(imdb_top_250_english) #read .csv into a dataframe\n",
    "    return data #return the dataframe\n",
    "\n",
    "\n",
    "\n",
    "def create_table_250(): #create a refined table and cut down the plot synopses\n",
    "    '''Picks certain columsn to reform a new dataframe.\n",
    "    Tokenize the plots, remove stopwords, add to a new column.'''\n",
    "    data = callimdblist() #call function to create the dataframe\n",
    "    data = data[['Rank', 'Title', 'Year', 'Rated', 'Genre', 'Director', 'Actors', 'Plot']] #refine the dataset\n",
    "    data['Tokens'] = '' #Initialize new column\n",
    "    for index, row in data.iterrows(): #for each plot, tokenize and remove stopwords\n",
    "        movie_plot = row['Plot'] #simplify the column to a colloqiual variable for easy calling\n",
    "        tokenized_list = word_tokenize(movie_plot) #tokenize the movie plot\n",
    "        list_without_punctuation = [word for word in tokenized_list if word.isalpha] #take out all punctuation from tokenized plot\n",
    "        stop_words = set(stopwords.words('english')) #set the list of stopwords\n",
    "        list_without_stopwords = [word for word in list_without_punctuation if not word in stop_words] #removes all stopwords from tokenized list\n",
    "        data.at[index, 'Tokens'] = list_without_stopwords #adds the tokenized list without stopwords to correct row, column\n",
    "    return data #return dataframe\n",
    "    \n",
    "    \n",
    "    \n",
    "def search_params(data): #user selects search category and term - passes those to search function\n",
    "    '''Requires a dataframe as an input. Asks user for search category and passes those to search_func'''\n",
    "    while True: #loop until appropriate input is received\n",
    "        choice = input(\"Would you like to search by: plot, actor, director, or genre? \") #taking user category selection\n",
    "        choice = str.lower(choice) #normalize user text\n",
    "        if choice == \"plot\": #if user chooses plot\n",
    "            column = \"Tokens\" #set search column to the tokenized plot\n",
    "            term = input(\"Please enter a single word to search for: \") #take user search term\n",
    "            search_func(term, column, data) #call search_func with given search term, category, and dataframe\n",
    "            menu_route = continuation_func(data) #get user choice\n",
    "            if menu_route == True: #if they want to go to menu, break -- otherwise re-loop\n",
    "                break\n",
    "        elif choice == \"actor\": #if user chooses actor\n",
    "            column = \"Actors\" #set search column to actors\n",
    "            term = input(\"Please enter a single name to search for: \") #take user search term\n",
    "            search_func(term, column, data) #call search_func with given search term, category, and dataframe\n",
    "            menu_route = continuation_func(data) #get user choice\n",
    "            if menu_route == True: #if they want to go to menu, break -- otherwise re-loop\n",
    "                break\n",
    "        elif choice == \"director\": #if user chooses director\n",
    "            column = \"Director\" #set search column to director\n",
    "            term = input(\"Please enter a single name to search for: \") #take user search term\n",
    "            search_func(term, column, data) #call search_func with given search term, category, and dataframe\n",
    "            menu_route = continuation_func(data) #get user choice\n",
    "            if menu_route == True: #if they want to go to menu, break -- otherwise re-loop\n",
    "                break\n",
    "        elif choice == \"genre\": #if user chooses genre\n",
    "            column = \"Genre\" #set search column to genre\n",
    "            term = input(\"Please enter a single word to search for: \") #take user search term\n",
    "            term = str.capitalize(term) #normalize the input\n",
    "            search_func(term, column, data) #call search_func with given search term, category, and dataframe\n",
    "            menu_route = continuation_func(data) #get user choice\n",
    "            if menu_route == True: #if they want to go to menu, break -- otherwise re-loop\n",
    "                break\n",
    "        else: #if user doesn't enter a valid selection\n",
    "            print(\"\\nYou did not make a valid selection. Please enter 'plot', 'actor', 'director', or 'genre'. \\n\") #error\n",
    "    return #return to the menu\n",
    "\n",
    "            \n",
    "            \n",
    "def search_func(search, column, table): #finds matching titles to search criteria\n",
    "    '''Finds matching titles to search criteria. Requires search term, category, and dataframe as inputs. '''\n",
    "    print(\"\\nSearch Results: \") #print list header\n",
    "    for index, row in table.iterrows(): #print titles of the films that match the search term in the plot\n",
    "        if search in row[column]: #if there is a match then print the film title\n",
    "            display(f\"{row['Title']}\")\n",
    "    return #exit out of this function\n",
    "                    \n",
    "\n",
    "def continuation_func(data): #logic to see what the user wants to do next\n",
    "    '''Requires a dataframe as input. Will query the user to see what they want to do next and execute the decision.'''\n",
    "    while True: #enter loop\n",
    "        print(\"Would you like to: \") #beginning of query\n",
    "        print(\"    Search the top 250 again? Enter '1' to search again. \") #option 1 offered to user\n",
    "        print(\"    Return to the main menu? Enter '2' to return. \") #option 2 offered to user\n",
    "        choice = input() #take user input\n",
    "        if choice == '1': #if user chooses option 1\n",
    "            menu_route = False #they do not want to return to the menu\n",
    "            break\n",
    "        elif choice == '2': #if user chooses option 2\n",
    "            menu_route = True #they DO want to return to the menu\n",
    "            break\n",
    "        else: #if they make an invalid selection\n",
    "            print(\"Please make a valid selection. Choose '1' to search again, or '2' to return. \") #return them to pick again\n",
    "    return menu_route #return selection of menu or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
